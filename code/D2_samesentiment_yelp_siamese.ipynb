{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Siamese Text Similarity"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **https://github.com/sainimohit23/siamese-text-similarity**\n",
    "  - https://github.com/MahmoudWahdan/Siamese-Sentence-Similarity\n",
    "  - https://github.com/avinashsai/Siamese-Recurrent-Architectures-for-Sentence-Similarity\n",
    "  - https://github.com/TharinduDR/Siamese-Recurrent-Architectures\n",
    "- https://nlp.stanford.edu/projects/glove/\n",
    "  - https://nlp.stanford.edu/data/glove.6B.zip\n",
    "- `conda install tensorflow-gpu`\n",
    "- monkeypatch: https://github.com/tensorflow/models/issues/9706#issuecomment-877788105\n",
    "- https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/\n",
    "- https://keras.io/examples/nlp/bidirectional_lstm_imdb/\n",
    "\n",
    "```bash\n",
    "conda install tensorflow-gpu  # conda install cudatoolkits etc.\n",
    "conda install jupyterlab\n",
    "#conda install Keras  # ?\n",
    "# monkeypatch tensorflow array_ops ...\n",
    "pip install numpy tqdm matplotlib scikit-learn pandas\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import csv\n",
    "import dataclasses\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Input, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "#from tqdm.keras import TqdmCallback\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices('GPU')"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "classes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# https://github.com/huggingface/transformers/blob/9f72e8f4e1e767c5f608dd135199e592255b8a69/src/transformers/data/processors/utils.py\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InputExample:\n",
    "    \"\"\"\n",
    "    A single training/test example for simple sequence classification.\n",
    "    Args:\n",
    "        guid: Unique id for the example.\n",
    "        text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "        text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "        label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "\n",
    "    guid: str\n",
    "    text_a: str\n",
    "    text_b: Optional[str] = None\n",
    "    label: Optional[str] = None\n",
    "\n",
    "    def to_json_string(self):\n",
    "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
    "        return json.dumps(dataclasses.asdict(self), indent=2) + \"\\n\"\n",
    "    \n",
    "\n",
    "class Split(Enum):\n",
    "    train = \"train\"\n",
    "    dev = \"dev\"\n",
    "    test = \"test\"\n",
    "    pred = \"pred\"\n",
    "\n",
    "\n",
    "class SameSentimentDataProcessor:\n",
    "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
    "    \n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"\n",
    "        Gets an example from a dict with tensorflow tensors.\n",
    "        Args:\n",
    "            tensor_dict: Keys and values should match the corresponding Glue\n",
    "                tensorflow_dataset examples.\n",
    "        \"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"sentence1\"].numpy().decode(\"utf-8\"),\n",
    "            tensor_dict[\"sentence2\"].numpy().decode(\"utf-8\"),\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "    \n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of :class:`InputExample` for the train set.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\"\n",
    "        )\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of :class:`InputExample` for the dev set.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\"\n",
    "        )\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of :class:`InputExample` for the test set.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\"\n",
    "        )\n",
    "\n",
    "    def get_pred_examples(self, data_dir):\n",
    "        \"\"\"Get prediction examples (no label in dataset).\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"pred.tsv\")), \"pred\"\n",
    "        )\n",
    "    \n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        return [\"0\", \"1\"]\n",
    "        \n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            # TODO: has headers?\n",
    "            # if i == 0:\n",
    "            #     continue\n",
    "            guid = \"%s-%s\" % (set_type, line[0])\n",
    "            text_a = line[1]\n",
    "            text_b = line[2]\n",
    "            label = None if set_type == \"pred\" else line[-1]\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label)\n",
    "            )\n",
    "        return examples\n",
    "\n",
    "    def tfds_map(self, example):\n",
    "        \"\"\"\n",
    "        Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts\n",
    "        examples to the correct format.\n",
    "        \"\"\"\n",
    "        if len(self.get_labels()) > 1:\n",
    "            example.label = self.get_labels()[int(example.label)]\n",
    "        return example\n",
    "\n",
    "    @classmethod\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "        with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "            return list(csv.reader(f, delimiter=\"\\t\", quotechar=quotechar))"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "EMBEDDING_DIM = 50  # 50, 100, 200, 300\n",
    "MAX_SEQUENCE_LENGTH = 256\n",
    "VALIDATION_SPLIT = 0.1  # ?\n",
    "RATE_DROP_LSTM = 0.17\n",
    "RATE_DROP_DENSE = 0.25\n",
    "NUMBER_LSTM = 50  # 15\n",
    "NUMBER_DENSE_UNITS = 50\n",
    "ACTIVATION_FUNCTION = 'relu'\n",
    "\n",
    "NUM_EPOCHS = 20  # 200\n",
    "BATCH_SIZE = 512  # 1024  # 64\n",
    "\n",
    "assert EMBEDDING_DIM in (50, 100, 200, 300)\n",
    "fn_vectors = \"../test/siamese-text-similarity/glove.6B.{}d.txt\".format(EMBEDDING_DIM)\n",
    "fn_data = \"./data/sentiment/yelp-pair-b\"\n",
    "path = \"data/siamese\"\n",
    "\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "fn_cached_vocab = os.path.join(path, \"cached_vocab_{}.p\".format(EMBEDDING_DIM))\n",
    "fn_cached_train = os.path.join(path, \"cached_{}_{}.p\".format(Split.train.value, MAX_SEQUENCE_LENGTH))\n",
    "fn_cached_dev = os.path.join(path, \"cached_{}_{}.p\".format(Split.dev.value, MAX_SEQUENCE_LENGTH))\n",
    "fn_cached_test = os.path.join(path, \"cached_{}_{}.p\".format(Split.test.value, MAX_SEQUENCE_LENGTH))\n",
    "fn_best_model = os.path.join(path, \"bestmodel_{}_{}_{}.txt\".format(MAX_SEQUENCE_LENGTH, NUM_EPOCHS, BATCH_SIZE))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "load data (prep text fn)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def load_tsv_data(data_dir, processor, mode=None):\n",
    "    if mode == Split.dev:\n",
    "        examples = processor.get_dev_examples(data_dir)\n",
    "    elif mode == Split.test:\n",
    "        examples = processor.get_test_examples(data_dir)\n",
    "    elif mode == Split.pred:\n",
    "        examples = processor.get_pred_examples(data_dir)\n",
    "    else:\n",
    "        examples = processor.get_train_examples(data_dir)\n",
    "\n",
    "    guid, text_a, text_b, label = list(), list(), list(), list()\n",
    "    for example in examples:\n",
    "        guid.append(example.guid)\n",
    "        text_a.append(example.text_a)\n",
    "        text_b.append(example.text_b)\n",
    "        label.append(example.label)\n",
    "        \n",
    "    guid = np.array(guid)\n",
    "    text_a = np.array(text_a)\n",
    "    text_b = np.array(text_b)\n",
    "    label = np.array(label)\n",
    "\n",
    "    return guid, text_a, text_b, label"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def clean_text(lines):\n",
    "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    cleaned = list()\n",
    "    for text in lines:\n",
    "        text = text.lower()\n",
    "        \n",
    "        text = re.sub(r\"i'm\", \"i am\", text)\n",
    "        text = re.sub(r\"he's\", \"he is\", text)\n",
    "        text = re.sub(r\"she's\", \"she is\", text)\n",
    "        text = re.sub(r\"it's\", \"it is\", text)\n",
    "        text = re.sub(r\"that's\", \"that is\", text)\n",
    "        text = re.sub(r\"what's\", \"that is\", text)\n",
    "        text = re.sub(r\"where's\", \"where is\", text)\n",
    "        text = re.sub(r\"how's\", \"how is\", text)\n",
    "        text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "        text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "        text = re.sub(r\"\\'re\", \" are\", text)\n",
    "        text = re.sub(r\"\\'d\", \" would\", text)\n",
    "        text = re.sub(r\"\\'re\", \" are\", text)\n",
    "        text = re.sub(r\"won't\", \"will not\", text)\n",
    "        text = re.sub(r\"can't\", \"cannot\", text)\n",
    "        text = re.sub(r\"n't\", \" not\", text)\n",
    "        text = re.sub(r\"n'\", \"ng\", text)\n",
    "        text = re.sub(r\"'bout\", \"about\", text)\n",
    "        text = re.sub(r\"'til\", \"until\", text)\n",
    "        # remove punctuation\n",
    "        text = re.sub(r\"[$-()\\\"#/@;:<>{}`+=~|.!?,'*-]\", \"\", text)\n",
    "                         \n",
    "        text = text.split()\n",
    "        text = [re_print.sub('', w) for w in text]\n",
    "        \n",
    "        cleaned.append(' '.join(text))\n",
    "\n",
    "    cleaned = np.array(cleaned)\n",
    "\n",
    "    return cleaned"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def read_glove_vectors(path):\n",
    "    \"\"\"\n",
    "    read Glove Vector Embeddings\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(path, encoding='utf8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        \n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            cur_word = line[0]\n",
    "            words.add(cur_word)\n",
    "            word_to_vec_map[cur_word] = np.array(line[1:], dtype=np.float64)\n",
    "\n",
    "    i = 1\n",
    "    words_to_index = {}\n",
    "    index_to_words = {}\n",
    "    for w in sorted(words):\n",
    "        words_to_index[w] = i\n",
    "        index_to_words[i] = w\n",
    "        i = i + 1\n",
    "\n",
    "    return words_to_index, index_to_words, word_to_vec_map\n",
    "\n",
    "\n",
    "def update_special_tokens(vocab_to_int, int_to_vocab, word_to_vec_map):\n",
    "    \"\"\" Special Tokens \"\"\"\n",
    "    for code in ['<PAD>', '<EOS>', '<UNK>', '<GO>']:\n",
    "        vocab_to_int[code] = len(vocab_to_int) + 1\n",
    "        int_to_vocab[len(int_to_vocab)+1] = code\n",
    "        word_to_vec_map[code] = np.random.random(50)\n",
    "    \n",
    "    return vocab_to_int, int_to_vocab, word_to_vec_map"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "preprocess"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def preprocess(fn_data, vocab_to_int, int_to_vocab, word_to_vec_map, max_len=15, mode=None, filter_too_long=False):\n",
    "    processor = SameSentimentDataProcessor()\n",
    "    \n",
    "    guid, sent1, sent2, labels = load_tsv_data(fn_data, processor, mode)\n",
    "\n",
    "    # --------------------------------\n",
    "\n",
    "    # clean text, remove contractions, tokenize\n",
    "    sent1 = clean_text(sent1)\n",
    "    sent2 = clean_text(sent2)\n",
    "\n",
    "    guid = np.array(guid)\n",
    "    sent1 = np.array(sent1)\n",
    "    sent2 = np.array(sent2)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # --------------------------------\n",
    "    \n",
    "    if filter_too_long:\n",
    "        # remove everything to long\n",
    "        def get_short_indices(length, sentences):\n",
    "            \"\"\"\n",
    "            Filter out sequences with length \"length\"\n",
    "            \"\"\"\n",
    "            idx = np.zeros((len(sentences)), dtype=bool)   \n",
    "            for num, sent in enumerate(sentences):\n",
    "                if len(sent.strip().split()) <= length:\n",
    "                    idx[num] = 1\n",
    "            return idx\n",
    "\n",
    "        dx = get_short_indices(max_len, sent1)\n",
    "        guid = guid[dx]\n",
    "        sent1 = sent1[dx]\n",
    "        sent2 = sent2[dx]\n",
    "        labels = labels[dx]\n",
    "\n",
    "        dx = get_short_indices(max_len, sent2)\n",
    "        guid = guid[dx]\n",
    "        sent1 = sent1[dx]\n",
    "        sent2 = sent2[dx]\n",
    "        labels = labels[dx]\n",
    "        \n",
    "    else:\n",
    "        # just trim first, so leaks do not contain the pad character\n",
    "        def _trim_too_long(length, sentences):\n",
    "            for idx in range(len(sentences)):\n",
    "                tokens = sentences[idx].strip().split()\n",
    "                tokens = tokens[:length]\n",
    "                sentences[idx] = \" \".join(tokens)\n",
    "            return sentences\n",
    "        \n",
    "        sent1 = _trim_too_long(max_len, sent1)\n",
    "        sent2 = _trim_too_long(max_len, sent2)\n",
    "\n",
    "    # --------------------------------\n",
    "\n",
    "    # encode labels\n",
    "    label_list = processor.get_labels()\n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "    labels = np.array([label_map[l] for l in labels])\n",
    "\n",
    "    # --------------------------------\n",
    "\n",
    "    # tokenize\n",
    "    sent1_tokenized = []\n",
    "    for sent in sent1:\n",
    "        li= []\n",
    "        for word in sent.strip().split():\n",
    "            if word in vocab_to_int.keys():\n",
    "                li.append(vocab_to_int[word])\n",
    "            else:\n",
    "                li.append(vocab_to_int['<UNK>'])\n",
    "        sent1_tokenized.append(li)\n",
    "\n",
    "    sent2_tokenized = []\n",
    "    for sent in sent2:\n",
    "        li= []\n",
    "        for word in sent.strip().split():\n",
    "            if word in vocab_to_int.keys(): \n",
    "                li.append(vocab_to_int[word])\n",
    "            else:\n",
    "                li.append(vocab_to_int['<UNK>'])\n",
    "        sent2_tokenized.append(li)\n",
    "\n",
    "    # --------------------------------\n",
    "\n",
    "    del sent1, sent2 #freeing up the memory\n",
    "    gc.collect()\n",
    "\n",
    "    # --------------------------------\n",
    "\n",
    "    # Keeping track of common words\n",
    "    leaks = [[len(set(x1)), len(set(x2)), len(set(x1).intersection(x2))] \n",
    "            for x1, x2 in zip(sent1_tokenized, sent2_tokenized)]\n",
    "    leaks = np.array(leaks)\n",
    "\n",
    "    # --------------------------------\n",
    "\n",
    "    # padding the sequences\n",
    "    sent1_padded = pad_sequences(sent1_tokenized, maxlen=max_len, padding='post', truncating='post', value=vocab_to_int['<PAD>'])\n",
    "    sent2_padded = pad_sequences(sent2_tokenized, maxlen=max_len, padding='post', truncating='post', value=vocab_to_int['<PAD>'])\n",
    "\n",
    "    # --------------------------------\n",
    "\n",
    "    del sent1_tokenized, sent2_tokenized #freeing up the memory\n",
    "    gc.collect()\n",
    "\n",
    "    # --------------------------------\n",
    "    \n",
    "    return (sent1_padded, sent2_padded, leaks, labels)"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def get_vocab(fn_vectors, fn_cached_vocab):\n",
    "    if os.path.exists(fn_cached_vocab):\n",
    "        with open(fn_cached_vocab, \"rb\") as fp:\n",
    "            vocab_to_int, int_to_vocab, word_to_vec_map = pickle.load(fp)\n",
    "    else:\n",
    "        vocab_to_int, int_to_vocab, word_to_vec_map = read_glove_vectors(fn_vectors)\n",
    "        vocab_to_int, int_to_vocab, word_to_vec_map = update_special_tokens(vocab_to_int, int_to_vocab, word_to_vec_map)\n",
    "\n",
    "        with open(fn_cached_vocab, \"wb\") as fp:\n",
    "            pickle.dump((vocab_to_int, int_to_vocab, word_to_vec_map), fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    return vocab_to_int, int_to_vocab, word_to_vec_map\n",
    "\n",
    "\n",
    "def get_samples(fn_data, mode, vocab_to_int, int_to_vocab, word_to_vec_map, fn_cached=None):\n",
    "    if fn_cached is None:\n",
    "        fn_cached = os.path.join(path, \"cached_{}_{}.p\".format(mode.value, MAX_SEQUENCE_LENGTH))\n",
    "\n",
    "    if os.path.exists(fn_cached):\n",
    "        print(\"Cached samples exist: {}\".format(fn_cached))\n",
    "        with open(fn_cached, \"rb\") as fp:\n",
    "            return pickle.load(fp)\n",
    "\n",
    "    sent1_padded, sent2_padded, leaks, labels = preprocess(\n",
    "        fn_data=fn_data,\n",
    "        vocab_to_int=vocab_to_int, int_to_vocab=int_to_vocab, word_to_vec_map=word_to_vec_map,\n",
    "        max_len=MAX_SEQUENCE_LENGTH,\n",
    "        mode=mode,\n",
    "    )\n",
    "\n",
    "    print(\"Write cached samples to: {}\".format(fn_cached))\n",
    "    with open(fn_cached, \"wb\") as fp:\n",
    "        pickle.dump((sent1_padded, sent2_padded, leaks, labels), fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    return sent1_padded, sent2_padded, leaks, labels"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def load_preprocess(filename):\n",
    "    with open(filename, mode='rb') as in_file:\n",
    "        return pickle.load(in_file)"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def create_test_data(sent1, sent2, vocab_to_int):\n",
    "    sent1 = clean_text(sent1)\n",
    "    sent2 = clean_text(sent2)\n",
    "    sent1 = np.array(sent1)\n",
    "    sent2 = np.array(sent2)\n",
    "\n",
    "    # --------------------------------\n",
    "    \n",
    "    def _trim_too_long(length, sentences):\n",
    "        for idx in range(len(sentences)):\n",
    "            tokens = sentences[idx].strip().split()\n",
    "            tokens = tokens[:length]\n",
    "            sentences[idx] = \" \".join(tokens)\n",
    "        return sentences\n",
    "\n",
    "    sent1 = _trim_too_long(max_len, sent1)\n",
    "    sent2 = _trim_too_long(max_len, sent2)\n",
    "\n",
    "    # --------------------------------\n",
    "\n",
    "    sent1_tokenized = []\n",
    "    for sent in sent1:\n",
    "        li= []\n",
    "        for word in sent.strip().split():\n",
    "            if word in vocab_to_int.keys():\n",
    "                li.append(vocab_to_int[word])\n",
    "            else:\n",
    "                li.append(vocab_to_int['<UNK>'])\n",
    "        sent1_tokenized.append(li)\n",
    "    \n",
    "    sent2_tokenized = []\n",
    "    for sent in sent2:\n",
    "        li= []\n",
    "        for word in sent.strip().split():\n",
    "            if word in vocab_to_int.keys(): \n",
    "                li.append(vocab_to_int[word])\n",
    "            else:\n",
    "                li.append(vocab_to_int['<UNK>'])\n",
    "        sent2_tokenized.append(li)\n",
    "\n",
    "    # --------------------------------\n",
    "        \n",
    "    del sent1, sent2 #freeing up the memory\n",
    "    gc.collect()\n",
    "\n",
    "    # --------------------------------\n",
    "    \n",
    "    # Keeping track of common words\n",
    "    leaks = [[len(set(x1)), len(set(x2)), len(set(x1).intersection(x2))] \n",
    "            for x1, x2 in zip(sent1_tokenized, sent2_tokenized)]\n",
    "    leaks = np.array(leaks)\n",
    "\n",
    "    # --------------------------------\n",
    "    \n",
    "    #padding the sequences\n",
    "    sent1_padded = pad_sequences(sent1_tokenized, maxlen=15, padding='post', truncating='post', value=vocab_to_int['<PAD>'])\n",
    "    sent2_padded = pad_sequences(sent2_tokenized, maxlen=15, padding='post', truncating='post', value=vocab_to_int['<PAD>'])\n",
    "\n",
    "    # --------------------------------\n",
    "    \n",
    "    del sent1_tokenized, sent2_tokenized #freeing up the memory\n",
    "    gc.collect()\n",
    "\n",
    "    # --------------------------------\n",
    "    \n",
    "    return (sent1_padded, sent2_padded, leaks)"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "model"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, words_to_index):\n",
    "    emb_dim = word_to_vec_map['pen'].shape[0]\n",
    "    vocab_size = len(words_to_index) + 1\n",
    "    emb_matrix = np.zeros((vocab_size, emb_dim))\n",
    "    \n",
    "    for word, index in words_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "    \n",
    "    #emb_matrix = tf.convert_to_tensor(emb_matrix, dtype=tf.float32) \n",
    "    #emb_layer = Embedding(vocab_size, emb_dim, embeddings_initializer=Constant(emb_matrix), trainable=False)\n",
    "    \n",
    "    emb_layer = Embedding(vocab_size, emb_dim, trainable=True)\n",
    "    emb_layer.build((None,))\n",
    "    emb_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return emb_layer"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def get_uncompiled_model(word_to_vec_map, vocab_to_int, leaks, labels):\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, vocab_to_int)\n",
    "    lstm_layer1 = Bidirectional(LSTM(NUMBER_LSTM, dropout=RATE_DROP_LSTM, recurrent_dropout=RATE_DROP_LSTM, return_sequences=True))\n",
    "    lstm_layer2 = Bidirectional(LSTM(NUMBER_LSTM, dropout=RATE_DROP_LSTM, recurrent_dropout=RATE_DROP_LSTM))\n",
    "    dropout_layer = Dropout(0.5)\n",
    "\n",
    "    seq1_inp = Input(shape=(MAX_SEQUENCE_LENGTH, ), dtype='int32', name='seq1_inp')\n",
    "    net1 = embedding_layer(seq1_inp)\n",
    "    net1 = lstm_layer1(net1)\n",
    "    net1 = dropout_layer(net1)\n",
    "    out1 = lstm_layer2(net1)\n",
    "\n",
    "    seq2_inp = Input(shape=(MAX_SEQUENCE_LENGTH, ), dtype='int32', name= 'seq2_inp')\n",
    "    net2 = embedding_layer(seq2_inp)\n",
    "    net2 = lstm_layer1(net2)\n",
    "    net2 = dropout_layer(net2)\n",
    "    out2 = lstm_layer2(net2)\n",
    "\n",
    "    leaks_inp = Input(shape=(leaks.shape[1],), name='leaks_inp')\n",
    "    leaks_out = Dense(units=int(NUMBER_DENSE_UNITS/2), activation=ACTIVATION_FUNCTION)(leaks_inp)\n",
    "\n",
    "    merged = concatenate([out1, out2, leaks_out])\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Dropout(RATE_DROP_DENSE)(merged)\n",
    "    merged = Dense(NUMBER_DENSE_UNITS, activation=ACTIVATION_FUNCTION)(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Dropout(RATE_DROP_DENSE)(merged)\n",
    "\n",
    "    # labels.shape[1]\n",
    "    preds = Dense(units=1, activation=\"sigmoid\", name='pred')(merged)\n",
    "\n",
    "    model = keras.models.Model(inputs=[seq1_inp, seq2_inp, leaks_inp], outputs=preds)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_compiled_model(word_to_vec_map, vocab_to_int, leaks, labels):\n",
    "    model = get_uncompiled_model(word_to_vec_map, vocab_to_int, leaks, labels)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def data_generator(sent1, sent2, leaks, labels, batch_size):\n",
    "    while True:\n",
    "        idx = np.random.randint(len(sent1), size= batch_size)\n",
    "        x1_batch = sent1[idx]\n",
    "        x2_batch = sent2[idx]\n",
    "        labels_batch = labels[idx]\n",
    "        leaks_batch = leaks[idx]\n",
    "\n",
    "        x_data = {\n",
    "            'seq1_inp': x1_batch,\n",
    "            'seq2_inp': x2_batch,\n",
    "            'leaks_inp': leaks_batch\n",
    "        }\n",
    "        y_data = {\n",
    "            'pred': labels_batch\n",
    "        }\n",
    "\n",
    "        yield (x_data, y_data)"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## prepare"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "if False:\n",
    "    ! rm {fn_cached_vocab}\n",
    "    ! rm {fn_cached_train} {fn_cached_dev} {fn_cached_test}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "vocab_to_int, int_to_vocab, word_to_vec_map = get_vocab(fn_vectors, fn_cached_vocab)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_ = get_samples(fn_data, Split.train, vocab_to_int, int_to_vocab, word_to_vec_map, fn_cached=fn_cached_train)\n",
    "_ = get_samples(fn_data, Split.dev, vocab_to_int, int_to_vocab, word_to_vec_map, fn_cached=fn_cached_dev)\n",
    "_ = get_samples(fn_data, Split.test, vocab_to_int, int_to_vocab, word_to_vec_map, fn_cached=fn_cached_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#vocab_to_int, int_to_vocab, word_to_vec_map = get_vocab(fn_vectors, fn_cached_vocab)\n",
    "#sent1, sent2, leaks, labels = get_samples(fn_data, Split.train, vocab_to_int, int_to_vocab, word_to_vec_map, fn_cached=fn_cached_train)\n",
    "#sent1_valid, sent2_valid, leaks_valid, labels_valid = get_samples(fn_data, Split.dev, vocab_to_int, int_to_vocab, word_to_vec_map, fn_cached=fn_cached_dev)\n",
    "\n",
    "vocab_to_int, int_to_vocab, word_to_vec_map = load_preprocess(fn_cached_vocab)\n",
    "sent1, sent2, leaks, labels = load_preprocess(fn_cached_train)\n",
    "sent1_valid, sent2_valid, leaks_valid, labels_valid = load_preprocess(fn_cached_dev)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "print(\"num train: \", len(labels))\n",
    "print(\"num dev:   \", len(labels_valid))\n",
    "\n",
    "if False:\n",
    "    np.random.seed(42)\n",
    "\n",
    "    idx_map = np.arange(len(labels))\n",
    "    idx_map = np.random.choice(idx_map, 30000, replace=False)\n",
    "    sent1, sent2, leaks, labels = sent1[idx_map], sent2[idx_map], leaks[idx_map], labels[idx_map]\n",
    "\n",
    "if True:\n",
    "    np.random.seed(43)\n",
    "\n",
    "    idx_map = np.arange(len(labels_valid))\n",
    "    idx_map = np.random.choice(idx_map, 10000, replace=False)\n",
    "    sent1_valid, sent2_valid, leaks_valid, labels_valid = sent1_valid[idx_map], sent2_valid[idx_map], leaks_valid[idx_map], labels_valid[idx_map]\n",
    "\n",
    "print(\"num train: \", len(labels))\n",
    "print(\"num dev:   \", len(labels_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num train:  359128\n",
      "num dev:    153912\n",
      "num train:  359128\n",
      "num dev:    10000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "labels = labels.astype(float)\n",
    "labels_valid = labels_valid.astype(float)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7)\n",
    "STAMP = 'lstm_%d_%d_%.2f_%.2f' % (NUMBER_LSTM, NUMBER_DENSE_UNITS, RATE_DROP_DENSE, RATE_DROP_LSTM)\n",
    "checkpoint_dir = os.path.join(path, 'checkpoints', str(int(time.time())))\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "bst_model_path = os.path.join(checkpoint_dir, STAMP + '.h5')\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=False)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(checkpoint_dir, \"logs\", \"{}\".format(time.time())))"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = get_compiled_model(word_to_vec_map, vocab_to_int, leaks, labels)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq1_inp (InputLayer)           [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "seq2_inp (InputLayer)           [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 256, 50)      20000250    seq1_inp[0][0]                   \n",
      "                                                                 seq2_inp[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 256, 100)     40400       embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256, 100)     0           bidirectional[0][0]              \n",
      "                                                                 bidirectional[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaks_inp (InputLayer)          [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 100)          60400       dropout[0][0]                    \n",
      "                                                                 dropout[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 25)           100         leaks_inp[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 225)          0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_1[1][0]            \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 225)          900         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 225)          0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50)           11300       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 50)           200         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50)           0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "pred (Dense)                    (None, 1)            51          dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,113,601\n",
      "Trainable params: 20,113,051\n",
      "Non-trainable params: 550\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "generator = data_generator(sent1, sent2, leaks, labels, BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "NUM_TRAIN_SAMPLES = len(labels)\n",
    "\n",
    "print(\"number of train samples: \", NUM_TRAIN_SAMPLES)\n",
    "print(\"batch size:              \", BATCH_SIZE)\n",
    "print(\"number of epochs:        \", NUM_EPOCHS)\n",
    "print(\"steps per epoch:         \", NUM_TRAIN_SAMPLES // BATCH_SIZE)\n",
    "\n",
    "# _ = \"\"\"\n",
    "H = model.fit(\n",
    "    x=generator,\n",
    "    steps_per_epoch=NUM_TRAIN_SAMPLES // BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        model_checkpoint,\n",
    "        tensorboard,\n",
    "        #TqdmCallback(verbose=0),\n",
    "    ],\n",
    "    #verbose=0,\n",
    "    validation_data=(\n",
    "        [sent1_valid, sent2_valid, leaks_valid],\n",
    "        labels_valid\n",
    "    ),\n",
    "    #validation_steps=NUM_TRAIN_SAMPLES // BS,\n",
    ")\n",
    "# \"\"\"\n",
    "\n",
    "_ = \"\"\"\n",
    "H = model.fit_generator(\n",
    "    generator,\n",
    "    steps_per_epoch=80,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        model_checkpoint,\n",
    "        tensorboard\n",
    "    ],\n",
    "    validation_data=(\n",
    "        [sent1_valid, sent2_valid, leaks_valid],\n",
    "        labels_valid\n",
    "    )\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "with open('bestmodel.txt', 'w') as file:\n",
    "    file.write(bst_model_path)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = min(NUM_EPOCHS, len(H.history[\"loss\"]))\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## predict"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('bestmodel.txt', 'r') as file:\n",
    "    best_model_path = file.read()\n",
    "\n",
    "model = keras.models.load_model(best_model_path)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "sent1_test, sent2_test, leaks_test, labels_test = load_preprocess(fn_cached_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds_test = model.predict(x=[sent1_test, sent2_test, leaks_test], verbose=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "preds_test[preds_test <= 0.5] = 0.\n",
    "preds_test[preds_test > 0.5] = 1.\n",
    "preds_test = preds_test.astype(\"int32\")\n",
    "\n",
    "# preds_test = (preds_test > 0.5).astype(\"int32\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(labels_test, preds_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83     28609\n",
      "           1       0.82      0.84      0.83     28396\n",
      "\n",
      "    accuracy                           0.83     57005\n",
      "   macro avg       0.83      0.83      0.83     57005\n",
      "weighted avg       0.83      0.83      0.83     57005\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "np.unique(labels_test, return_counts=True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0, 1]), array([28609, 28396]))"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "np.unique(preds_test, return_counts=True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int32), array([28009, 28996]))"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vocab_to_int, _, _ = load_preprocess(fn_cached_vocab)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sent_pairs = [\n",
    "    ['This is an example.', 'This is an example.'],\n",
    "    ['This is an example.', 'This is not a good example.'],\n",
    "    ['What can make Physics easy to learn?', 'How can you make physics easy to learn?'],\n",
    "    ['How many times a day do a clocks hands overlap?', 'What does it mean that every time I look at the clock the numbers are the same?'],\n",
    "    ['Fishes do not fly.', 'I like eating ice cream when the weather is really hot.'],\n",
    "]\n",
    "sent1, sent2 = zip(*sent_pairs)\n",
    "\n",
    "test_data_x1, test_data_x2, leaks_test = create_test_data(sent1, sent2, vocab_to_int)\n",
    "\n",
    "preds = model.predict([test_data_x1, test_data_x2, leaks_test], verbose=1)\n",
    "\n",
    "print(\"\\n\")\n",
    "for i in range(len(preds)):\n",
    "    print(\"Sentance 1: \" + sent1[i])\n",
    "    print(\"Sentance 2: \" + sent2[i])\n",
    "    print(\"Similarity Score: \" + str(calculate_total_score(preds[i])))\n",
    "    print(\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labels[20:30]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}