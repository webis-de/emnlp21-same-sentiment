{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset preparation - SameSentiment Amazon - Base"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers.trainer_utils import set_seed\n",
    "\n",
    "tqdm.pandas()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# see readme.txt file for more details\n",
    "fn_base = Path(\"data_raw/sentiment/amazon_v1\")\n",
    "\n",
    "fn_reviews_kindle = fn_base / \"reviews_Kindle_Store_5.json.gz\"\n",
    "\n",
    "data_amazon_path = Path(\"data/sentiment/amazon_v1/\")\n",
    "\n",
    "fn_amazon_kindle_df = data_amazon_path / \"kindle_pairs_df.p\"\n",
    "fn_amazon_df = data_amazon_path / \"pairs_df.p\"\n",
    "\n",
    "data_amazon_b_tdt_path = Path(\"data/sentiment/amazon-pair-b/\")\n",
    "data_amazon_b_rand_tdt_path = Path(\"data/sentiment/amazon-pair-rand-b/\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fn_amazon_kindle_df.parent.mkdir(parents=True, exist_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from data_prep import load_amazon_reviews\n",
    "from data_prep import load_amazon_reviews_all\n",
    "\n",
    "from data_prep_sentiment_amazon_v1 import make_inv_topic2id\n",
    "from data_prep_sentiment_amazon_v1 import make_inv_id2topic\n",
    "\n",
    "from data_prep import filter_min_review_freq\n",
    "from data_prep import filter_both_good_bad\n",
    "\n",
    "from data_prep import make_pairs_good_bad\n",
    "#from data_prep import make_pairs_good_bad_over_business\n",
    "from data_prep import make_pairs_negative\n",
    "#from data_prep import make_pairs_negative_over_business\n",
    "\n",
    "from data_prep import make_or_load_pairs\n",
    "from data_prep import make_or_load_pairs_over_businesses\n",
    "\n",
    "from data_prep import split_df\n",
    "from data_prep import write_pair_tdt_tsv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load raw data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Load reviews ...\")\n",
    "# df = load_amazon_reviews(fn_reviews_kindle)\n",
    "# df[\"topic\"] = \"Kindle\"\n",
    "df = load_amazon_reviews_all(fn_base)\n",
    "print(f\"  got: {len(df)} reviews\")\n",
    "\n",
    "print(\"Filter min reviews per id (asin) ...\")\n",
    "print(f\"  before: {len(df)}\")\n",
    "df = filter_min_review_freq(df, min_ratings=5)\n",
    "print(f\"  after:  {len(df)}\")\n",
    "\n",
    "print(\"Filter both good/bad per id (asin) ...\")\n",
    "print(f\"  before: {len(df)}\")\n",
    "df = filter_both_good_bad(df)\n",
    "print(f\"  after:  {len(df)}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if \"topic\" not in df.columns:\n",
    "    df[\"topic\"] = \"amazon\"\n",
    "\n",
    "inv_bid_cats = make_inv_id2topic(make_inv_topic2id(df))\n",
    "inv_bid_cats = {k: [v] for k, v in inv_bid_cats.items()}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df[\"goodness\"].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# inv_bid_cats = dict()\n",
    "\n",
    "num_pairs_per_class = 2\n",
    "num_pairs_negative = 2 * num_pairs_per_class\n",
    "\n",
    "#pairs_good, pairs_bad = make_pairs_good_bad(df, inv_bid_cats, num_pairs_per_class=num_pairs_per_class)\n",
    "#pairs_neg = make_pairs_negative(df, inv_bid_cats, num_pairs_negative, repeatable_on_side=False)\n",
    "#print(f\"#good: {len(pairs_good)}, #bad: {len(pairs_bad)}, #neg {len(pairs_neg)}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "set_seed(42)\n",
    "\n",
    "#df_traindev = make_or_load_pairs(df, inv_bid_cats, str(fn_amazon_kindle_df), num_pairs_per_class=2)\n",
    "df_traindev = make_or_load_pairs(df, inv_bid_cats, str(fn_amazon_df), num_pairs_per_class=2)\n",
    "traindev_df = df_traindev"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Store test set?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fn_amazon_df = data_amazon_path / \"df_traindev_test.p\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# store\n",
    "traindev_df, test_df = split_df(traindev_df, ratio=0.1, do_shuffle=True, random_state=42, name_train=\"traindev\", name_dev=\"test\")\n",
    "\n",
    "with open(fn_amazon_df, \"wb\") as fp:\n",
    "    pickle.dump(traindev_df, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump(test_df, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write train/dev/test sets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open(fn_amazon_df, \"rb\") as fp:\n",
    "    traindev_df = pickle.load(fp)\n",
    "    test_df = pickle.load(fp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "root_path = data_amazon_b_tdt_path\n",
    "#root_path = data_amazon_b_rand_tdt_path"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "write_pair_tdt_tsv(root_path, traindev_df, split_test=0.1, split_dev=0.3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# symlink pred.tsv\n",
    "! ln -s test.tsv {root_path}/pred.tsv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"@ \", root_path, \"\\n\")\n",
    "! ls -lh {root_path}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "! rm data/sentiment/amazon-pair-b/cached_*"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#model_name = \"bert-base-uncased\"\n",
    "#model_name = \"bert-base-cased\"\n",
    "#model_name = \"distilroberta-base\"\n",
    "model_name = \"distilbert-base-cased\"\n",
    "#model_name = \"albert-base-v2\"\n",
    "\n",
    "data_name = \"amazon-pair-b\"\n",
    "#data_name = \"amazon-pair-rand-b\" ## over businesses\n",
    "\n",
    "seq_len = 256\n",
    "batch_size = 32\n",
    "acc_steps = 64\n",
    "num_epoch = 2\n",
    "cuda_devs = \"1\"\n",
    "\n",
    "run_name = f\"{model_name.replace('/', '-')}-{data_name}_{seq_len}_{batch_size}-acc{acc_steps}_{num_epoch}\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create folder for logging\n",
    "! mkdir -p ./output_sent_logs/{run_name}\n",
    "\n",
    "! \\\n",
    "    CUDA_VISIBLE_DEVICES={cuda_devs} \\\n",
    "    python trainer.py \\\n",
    "    --do_train --do_eval --do_test \\\n",
    "    --model_name_or_path {model_name} \\\n",
    "    --task_name same-b \\\n",
    "    --data_dir ./data/sentiment/{data_name} \\\n",
    "    --output_dir ./output_sent/{run_name} \\\n",
    "    --run_name {run_name} \\\n",
    "    --per_device_eval_batch_size {batch_size} \\\n",
    "    --per_device_train_batch_size {batch_size} \\\n",
    "    --gradient_accumulation_steps {acc_steps} \\\n",
    "    --logging_steps 5000 \\\n",
    "    --save_steps 10000 \\\n",
    "    --save_total_limit 3 \\\n",
    "    --num_train_epochs {num_epoch} \\\n",
    "    --max_seq_length {seq_len} \\\n",
    "    --evaluation_strategy epoch \\\n",
    "    > >(tee -a ./output_sent_logs/{run_name}/stdout.log) \\\n",
    "    2> >(tee -a ./output_sent_logs/{run_name}/stderr.log >&2)\n",
    "\n",
    "# --overwrite_output_dir \\\n",
    "# --overwrite_cache \\\n",
    "# --eval_steps 128 \\\n",
    "# --evaluation_strategy steps \\\n",
    "# --load_best_model_at_end \\"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if False:\n",
    "    # _csv.Error: line contains NUL\n",
    "    from pathlib import Path\n",
    "    fn = Path(\"data/sentiment/amazon-pair-b/dev.tsv\")\n",
    "    fn.write_text(\" \".join(fn.read_text().split(\"\\0\")))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# evaluate senti\n",
    "\n",
    "run_name_ = run_name\n",
    "task_name = \"yelp-pair-b\"\n",
    "load_name = f\"./output_sent/{run_name}\"\n",
    "run_name = f\"{run_name}-senti-{task_name}\"\n",
    "log_dir = f\"./output_sent_logs/{run_name}\"\n",
    "\n",
    "# create folder for logging\n",
    "! mkdir -p {log_dir}\n",
    "\n",
    "! \\\n",
    "    CUDA_VISIBLE_DEVICES={cuda_devs} \\\n",
    "    python trainer.py \\\n",
    "    --do_test \\\n",
    "    --model_name_or_path {load_name} \\\n",
    "    --task_name same-b \\\n",
    "    --data_dir ./data/sentiment/{task_name} \\\n",
    "    --output_dir ./output/{run_name} \\\n",
    "    --overwrite_output_dir \\\n",
    "    --overwrite_cache \\\n",
    "    --run_name {run_name} \\\n",
    "    --max_seq_length {seq_len} \\\n",
    "    --per_device_eval_batch_size {batch_size} \\\n",
    "    --logging_steps 100 \\\n",
    "    > >(tee -a {log_dir}/stdout.log) \\\n",
    "    2> >(tee -a {log_dir}/stderr.log >&2)\n",
    "\n",
    "# task_name = yelp-pair-b / yelp-pair-rand-b / amazon-pair-b\n",
    "# --data_dir ./data/sentiment/{task_name} \\\n",
    "# task_name = cross / within / artificial\n",
    "# --data_dir ./data/argmining_emnlp21/{task_name} \\"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}